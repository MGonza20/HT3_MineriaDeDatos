---
title: "notebook"
output: html_document
date: "2023-03-02"
editor_options: 
  markdown: 
    wrap: 72
---

# Hoja de trabajo 03 - Regresión Lineal

```{r libraries}
library(dplyr)
library(knitr)
library(ggplot2)
library(cluster)
library(factoextra)
require(caret)
library(corrplot)
library(Metrics)
library(boot)

library(hopkins)
library(e1071)
library(mclust)
library(fpc) 
library(NbClust) 
library(GGally)
library(FeatureImpCluster)
library(pheatmap)
library(ggplot2)
```

```{r confi dplyr}
options(dplyr.summarise.inform = FALSE)
```

```{r train data}
data <- read.csv("train.csv")
```

## 2. Análisis Exploratorio

### ¿Cuál es la Zona más cara?

```{r average_price_per_zone}
grouped_data <- data %>% group_by(MSZoning)
agg_tbl <- grouped_data %>% summarise(median(SalePrice))
grouped_dataset <- as.data.frame(agg_tbl)
colnames(grouped_dataset)[colnames(grouped_dataset) == "MSZoning"] ="Zona"
colnames(grouped_dataset)[colnames(grouped_dataset) == "median(SalePrice)"] ="Promedio de Precio (USD)"
grouped_dataset <- grouped_dataset[order(grouped_dataset$`Promedio de Precio (USD)`, decreasing = TRUE), ]
kable(grouped_dataset, caption = "Promedio de ventas por cada zona")
```

Un 50% de las casas en la zona `Floating Village Residential` se venden
por arriba de los 205940.00 USD. Posteriormente sigue
`Residential Low Density`.

### ¿En qué vecindario se ubican las casas con mayor área en su terreno?

```{r area_per_neighborhood}
grouped_area_data <- data %>% group_by(Neighborhood)
area_with_median <- grouped_area_data %>% summarise(median(LotArea))
grouped_dataset_lot <- as.data.frame(area_with_median)
colnames(grouped_dataset_lot)[colnames(grouped_dataset_lot) == "Neighborhood"] ="Vecindario"
colnames(grouped_dataset_lot)[colnames(grouped_dataset_lot) == "median(LotArea)"] ="Area del terreno ft^2"
grouped_dataset_lot <- grouped_dataset_lot[order(grouped_dataset_lot$`Area del terreno ft^2`, decreasing = TRUE), ]
kable(grouped_dataset_lot[0:5,], caption = "Mediana de area por cada vecindario")
```

```{r plot_area_per_neighborhood}
ggplot(grouped_dataset_lot[0:5,], aes(x=Vecindario, y=`Area del terreno ft^2`)) +
geom_bar(stat="identity", fill="steelblue") 
```

La información nos demuestra que Clear Creek es el vecindario que tiene
los terrenos con mayor área. Un 50% de los terrenos tiene un área mayor
a 17575.0 pies cuadrados.

### ¿En qué año hubo más remodelaciones?

```{r remodelation_by_year}
data_with_remodelation <- data[data$YearBuilt != data$YearRemodAdd,]
```

En el dataset hay `r nrow(data_with_remodelation)` registros de casas
que fueron remodeladas. A continuación agrupamos por año la cantidad de
remodelaciones.

```{r group_remodelation_by_year}
grouped_remodelation_data <- data_with_remodelation %>% group_by(YearRemodAdd)
year_with_count <- grouped_remodelation_data %>% summarise(total_count=n(),
            .groups = 'drop')

grouped_remodelation <- as.data.frame(year_with_count)
colnames(grouped_remodelation)[colnames(grouped_remodelation) == "YearRemoAdd"] ="Año"
colnames(grouped_remodelation)[colnames(grouped_remodelation) == "total_count"] ="Cantidad de casas remodeladas"
grouped_remodelation <- grouped_remodelation[order(grouped_remodelation$`Cantidad de casas remodeladas`, decreasing = TRUE), ]
kable(grouped_remodelation[0:5,], caption = "Numero de casas Remodeladas por año")

```

Los 5 años con más casas remodeladas son 1950, 2006, 2007, 2005 y 2000
respectivamente. Es importante notar que en 1950 hay mucha más
diferencia que con los demás años.

```{r}
most_remodelated_zone_1950 <- tail(names(sort(table(data_with_remodelation[data_with_remodelation$YearRemodAdd == "1950",]$MSZoning))), 1)

most_remodelated_zone_2006 <- tail(names(sort(table(data_with_remodelation[data_with_remodelation$YearRemodAdd == "2006",]$MSZoning))), 1)

most_remodelated_zone_2007 <- tail(names(sort(table(data_with_remodelation[data_with_remodelation$YearRemodAdd == "2007",]$MSZoning))), 1)

```

La mayoría de las remodelaciones pertenecen a la zona
`RL - Residencial de baja densidad`.

### ¿Cuáles son los materiales más utilizados para la fundación de las casas?

```{r most_used_foundation}
grouped_foundation_data <- data %>% group_by(Foundation)
foundation_with_count <- grouped_foundation_data %>% summarise(total_count=n(),
            .groups = 'drop')

grouped_foundation <- as.data.frame(foundation_with_count)
colnames(grouped_foundation)[colnames(grouped_foundation) == "Foundation"] ="Material para la base"
colnames(grouped_foundation)[colnames(grouped_foundation) == "total_count"] ="Cantidad de casas"
grouped_foundation <- grouped_foundation[order(grouped_foundation$`Cantidad de casas`, decreasing = TRUE), ]
kable(grouped_foundation[0:5,], caption = "Numero de casas por cada material de base")

```

La mayoría de casas están hechas de concreto. Puede ser que un tipo
menos común, pero más caro, como el ladrillo signifique un precio más
alto.

### ¿Qué tipos de casa son más comunes?

```{r}
grouped_type_data <- data %>% group_by(BldgType)
type_count <- grouped_type_data %>% summarise(total_count=n(), .groups = 'drop')

grouped_type <- as.data.frame(type_count)
colnames(grouped_type)[colnames(grouped_type) == "BldgType"] ="Tipo de casa"
colnames(grouped_type)[colnames(grouped_type) == "total_count"] ="Cantidad"
grouped_type <- grouped_type[order(grouped_type$`Cantidad`, decreasing = TRUE), ]
kable(grouped_type, caption = "Conteo de tipo de casas")

```
Los tipo de casas más comunes son de 1 familia y de tipo town house.


### ¿Que vecindarios tienen un mayor rango de precios?

```{r}

grouped_data <- data %>% group_by(Neighborhood) %>% summarise(minPrice = min(SalePrice), maxPrice = max(SalePrice))
grouped <- grouped_data %>% mutate(priceRange = maxPrice - minPrice) %>% arrange(desc(priceRange))

colnames(grouped)[colnames(grouped) == "Neighborhood"] = "Vecindario"
colnames(grouped)[colnames(grouped) == "minPrice"] = "Precio Mínimo (USD)"
colnames(grouped)[colnames(grouped) == "maxPrice"] = "Precio Máximo (USD)"
colnames(grouped)[colnames(grouped) == "priceRange"] = "Rango de Precios (USD)"

kable(head(grouped, 3), caption = "Top 3 - Vecindarios con mayor rango de precios")


```
Los vecindarios con mayor rango de precios son NoRidge, NridgHt y OldTown. Se puede observar que el rango de precios de NridgHt y OldTown es similar, sin embargo es necesario tomar en cuenta que el precio mínimo de OldTown es mucho menor al de NridgHt.


### ¿Cuál proporción de casas en cada zona?
```{r}
zone_counts <- data %>% count(MSZoning) %>% mutate(Proporcion = prop.table(n) * 100) %>% 
rename(Zona = MSZoning, Cantidad = n) %>% mutate(Proporcion = paste0(round(Proporcion, 2), "%")) %>%
arrange(desc(Cantidad))
kable(zone_counts, caption = "Proporción de casas por zona")
```
Se puede observar que la zona en donde hay mayor proporción de casas es la zona RL, seguido de RM tomando en cuenta que la proporción de casas en esta zona es considerablemente menor así como en las zonas FV, RH y C(all).


### ¿Cuáles son las características más comunes de las casas que se venden por encima del precio medio?

```{r}
price_mean_up <- mean(data$SalePrice)
houses_mean_above <- subset(data, SalePrice > price_mean_up)
ggplot(data = houses_mean_above, aes(x = MSZoning)) +geom_bar()
ggplot(data = houses_mean_above, aes(x = BldgType)) +geom_bar()
ggplot(data = houses_mean_above, aes(x = HouseStyle)) +geom_bar()
ggplot(data = houses_mean_above, aes(x = GarageType)) +geom_bar()
```

Las características más comunes son las siguientes: 1) Zona donde se
ubica las casas: RL (Casa residencial de baja densidad) 2) Tipo de
vivienda: 1Fam (Unifamiliar) 3) Estilo de la casa: 1Story (Un nivel) 4)
Tipo de Garaje: Attchd (Adjuntada a la casa)

### ¿Cuántas casas tienen piscina o garaje? ¿Como se relacionan estas características con el precio de venta?

```{r}
print("Counting Pools And Garages")
nrow(data) - table(data$PoolArea > 0)
nrow(data) - nrow(data[data$GarageType=="NA",])
print("")
print("Relation with the seal price")
tapply(data$SalePrice, data$PoolQC > 0, mean)
tapply(data$SalePrice, data$GarageType=="NA", mean)

```

1453 casas tienen psicina 1379 casas cuentan con garaje

Como se puede ver si influyen la relación con el precio, las piscinas suelen elevar el precio de las casas

### ¿Cómo se distribuyen las ventas de casas a lo largo del tiempo entre los diferentes periodos?

```{r}
ggplot(data = data, aes(x = factor(YrSold))) +
  geom_bar(fill = "green") +
  ggtitle("Ventas de casas por año") +
  xlab("Año") +
  ylab("Cantidad de ventas")

ggplot(data = data, aes(x = YrSold, y = SalePrice)) +
  geom_line(color = "green") +
  ggtitle("Tendencia del precio de venta") +
  xlab("Año") +
  ylab("Precio de venta promedio")
```

Como se puede ver en las dos gráficas presentadas desde el año 2006 al
2009 existio una tendencia donde subía y bajan las ventas de las casas.
Pero desde 2010 este fue en bajando.

### Preprocesamiento de datos

```{r neihborhood values}
columns_used <- c()
neighborhoodNames <- c("NoRidge", "NridgHt", "StoneBr", "Timber", "Veenker", "Somerst", "ClearCr", "Crawfor", "CollgCr", "Blmngtn", "Gilbert", "NWAmes", "SawyerW", "Mitchel", "NAmes", "NPkVill", "SWISU", "Blueste", "Sawyer", "OldTown", "Edwards", "BrkSide", "BrDale", "IDOTRR", "MeadowV")

for(n in 1:length(neighborhoodNames)) {
  # Variable minuscula para nuestro uso.
  data$neighborhood[data$Neighborhood == neighborhoodNames[n]] <- n
}
columns_used <- append(columns_used, "neighborhood")

hs <- c("1Story", "2Story",	"1.5Fin",	"SLvl", "SFoyer")

for(n in 1:length(hs)) {
  # Variable minuscula para nuestro uso.
  data$houseStyle[data$HouseStyle == hs[n]] <- n
}
columns_used <- append(columns_used, "houseStyle")

 data$houseZone[data$MSZoning == "A"] <- 1
 data$houseZone[data$MSZoning == "C"] <- 2
 data$houseZone[data$MSZoning == "FV"] <- 3
 data$houseZone[data$MSZoning == "I"] <- 4
 data$houseZone[data$MSZoning == "RH"] <- 5
 data$houseZone[data$MSZoning == "RL"] <- 6
 data$houseZone[data$MSZoning == "RP"] <- 7
 data$houseZone[data$MSZoning == "RM"] <- 8
 columns_used <- append(columns_used, "houseZone")

data$houseUtilities[data$Utilities == "AllPub"] <- 1
data$houseUtilities[data$Utilities == "NoSewr"] <- 2
data$houseUtilities[data$Utilities == "NoSeWa"] <- 3
data$houseUtilities[data$Utilities == "ELO"] <- 4
columns_used <- append(columns_used, "houseUtilities")

data$roadAccess[data$Condition1 == "Artery"] <- 1
data$roadAccess[data$Condition1 == "Feedr"] <- 2
data$roadAccess[data$Condition1 == "Norm"] <- 3
data$roadAccess[data$Condition1 == "RRNn"] <- 4
data$roadAccess[data$Condition1 == "RRAn"] <- 5
data$roadAccess[data$Condition1 == "PosN"] <- 6
data$roadAccess[data$Condition1 == "PosA"] <- 7
data$roadAccess[data$Condition1 == "RRNe"] <- 8
data$roadAccess[data$Condition1 == "RRAe"] <- 9
columns_used <- append(columns_used, "roadAccess")

data$remodelated[data$YearBuilt != data$YearRemodAdd] <- 1
data$remodelated[data$YearBuilt == data$YearRemodAdd] <- 0
columns_used <- append(columns_used, "remodelated")

data$roofStyle[data$RoofStyle == "Flat"]  <- 1
data$roofStyle[data$RoofStyle == "Gable"]  <- 2
data$roofStyle[data$RoofStyle == "Gambrel"]  <- 3
data$roofStyle[data$RoofStyle == "Hip"]  <- 4
data$roofStyle[data$RoofStyle == "Mansard"]  <- 5
data$roofStyle[data$RoofStyle == "Shed"]  <- 6
columns_used <- append(columns_used, "roofStyle")

data$roofMaterial[data$RoofMatl == "ClyTile"] <- 1
data$roofMaterial[data$RoofMatl == "CompShg"] <- 2
data$roofMaterial[data$RoofMatl == "Membran"] <- 3
data$roofMaterial[data$RoofMatl == "Metal"] <- 4
data$roofMaterial[data$RoofMatl == "Roll"] <- 5
data$roofMaterial[data$RoofMatl == "Tar&Grv"] <- 6
data$roofMaterial[data$RoofMatl == "WdShake"] <- 7
data$roofMaterial[data$RoofMatl == "WdShngl"] <- 8
columns_used <- append(columns_used, "roofMaterial")

data$overallQuality <- data$OverallQual
columns_used <- append(columns_used, "overallQuality")

data$overallCondition <- data$OverallCond
columns_used <- append(columns_used, "overallCondition")


data$exteriorCondition[data$ExterCond == "Po"] <- 1
data$exteriorCondition[data$ExterCond == "Fa"] <- 2
data$exteriorCondition[data$ExterCond == "TA"] <- 3
data$exteriorCondition[data$ExterCond == "Gd"] <- 4
data$exteriorCondition[data$ExterCond == "Ex"] <- 5
columns_used <- append(columns_used, "exteriorCondition")

data$foundationMaterial[data$Foundation == "BrkTil"] <- 1
data$foundationMaterial[data$Foundation == "CBlock"] <- 2
data$foundationMaterial[data$Foundation == "PConc"] <- 3
data$foundationMaterial[data$Foundation == "Slab"] <- 4
data$foundationMaterial[data$Foundation == "Stone"] <- 5
data$foundationMaterial[data$Foundation == "Wood"] <- 6
columns_used <- append(columns_used, "foundationMaterial")

data$basement[is.na(data$BsmtQual)] <- 0
data$basement[!is.na(data$BsmtQual)] <- 1
columns_used <- append(columns_used, "basement")

data$basementCondition[data$BsmtCond == "Ex"] <- 3
data$basementCondition[data$BsmtCond == "Gd"] <- 2
data$basementCondition[data$BsmtCond != "Ex"] <- 1
data$basementCondition[data$BsmtCond != "Gd"] <- 1
data$basementCondition[is.na(data$BsmtCond)] <- 0
columns_used <- append(columns_used, "basementCondition")

data$fireplace[is.na(data$FireplaceQu)] <- 0
data$fireplace[!is.na(data$FireplaceQu)] <- 1
columns_used <- append(columns_used, "fireplace")

data$garageArea <- data$GarageArea
columns_used <- append(columns_used, "garageArea")

data$pool[is.na(data$PoolQC)] <- 0
data$pool[!is.na(data$PoolQC)] <- 1
columns_used <- append(columns_used, "pool")

data$additionalFeature[is.na(data$MiscFeature)] <- 0
data$additionalFeature[!is.na(data$MiscFeature)] <- 1
columns_used <- append(columns_used, "additionalFeature")

data$livingArea <- data$GrLivArea
columns_used <- append(columns_used, "livingArea")

data$yearBuilt <- data$YearBuilt
columns_used <- append(columns_used, "yearBuilt")


data$salePrice <- data$SalePrice
columns_used <- append(columns_used, "salePrice")

tv <- c("WD", "Oth", "New", "ConLw", "ConLI", "ConLD", "Con", "CWD", "COD")

for(n in 1:length(tv)) {
  # Variable minuscula para nuestro uso.
  data$saleType[data$SaleType == tv[n]] <- n
}
columns_used <- append(columns_used, "saleType")

msz <- c("FV", "RL", "RH", "RM" , "C (all)")

for(n in 1:length(msz)) {
  # Variable minuscula para nuestro uso.
  data$mSZoning[data$MSZoning == msz[n]] <- n
}
columns_used <- append(columns_used, "mSZoning")

```

### Borrando valores inneceesarios

```{r}
cleanData <- subset(data, select = columns_used)
```

## 3. Clustering

Agrupamiento de las columnas más importantes
``` {r}
# Definir las columnas más importantes
important_cols <- c("YrSold", "SalePrice", "YearBuilt", "YearRemodAdd", "PoolArea", "GarageArea", "OverallQual", "OverallCond", "LotFrontage", "LotArea", "GarageCars")
# Normalizar variables numericas
cols_num_norm <- data[,important_cols] <- mutate_if(data[,important_cols], is.numeric, scale)
```

Resumen de las columnas a utilizar para llevar a cabo el clustering
```{r}
print(summary(data[,important_cols]))
```

### Hopkins
```{r}
set.seed(123)
hopkins(data[, important_cols], m=1400)
```

El resultado es de 0.9999868, el cual indica una tendencia a clustering alta ya que es un valor cerca a 1.

### Evaluación Visual de Tendencia de la data (VAT)
``` {r}
data_dist <- dist(data[, important_cols])
fviz_dist(data_dist, show_labels=F)
```

Como se puede observar el método de hopkins esta en lo correcto y se puede confiar 
en el resultado dado de VAT ya que muestra patrones de agrupamiento en general.

### Determinar numero optimo de clusters

```{r kmedias}
cols_num_norm_w <- na.omit(cols_num_norm)
fviz_nbclust(cols_num_norm_w, kmeans, method = "gap")
```

El numero optimo de clusters es 4

``` {r}
number_clusters <- 4
```

### K-Means para clustering

``` {r}
km <- kmeans(cols_num_norm_w, centers = number_clusters, iter.max = 100)
km$size
```

``` {r}
fviz_cluster(km, cols_num_norm_w)
```

Como se puede ver los datos si estan agrupados, él único que muestra un mínimo de 
dispersión es el primer cluster (de color rojo)

### Clustering Jerarquico

``` {r}
hc<-hclust(data_dist, method = "ward.D2")
plot(hc, cex=0.5, axes=FALSE)
rect.hclust(hc,k=number_clusters)
```

También se puede ver que los clusters estan agrupados. En efecto VAT estaba en lo correcto.

## 4. Dividiendo los datos en entrenamiento y prueba
Dividimos el test de datos en un 75% para entrenamiento y un 25% para pruebas. Utilizamos el metodo de bootstraping porque nos asegura que la distribución de la data toma en cuenta la población total. Es decir, no tendremos un sesgo genrado por cómo la información está organizada.
``` {r}
set.seed(5)
expectedResult <- cleanData$salePrice
partition <- createDataPartition(y=expectedResult,
                                 p=.75,
                                 list=F)

trainingSet <- cleanData[partition,]
testingSet <- cleanData[-partition,]
```

## 5. Ingeniería de los Datos

Visualizamos la matriz de correlación para ver tendencias en la data.
```{r}
correlations <- cor(cleanData[,c("neighborhood", "yearBuilt", "overallCondition", "overallQuality", "houseZone", "houseUtilities")], use="pairwise.complete.obs")
corrplot(correlations, method="circle", type="lower",  sig.level = 0.01, insig = "blank")
```
De esta figura obtenemos las siguientes conclusiones:
- El año en el que se hizo la casa está correlacionado con el vecindario en el que se encuentra.
- La condición de la casa tienen una correlación ligeramente negativa. Puede ser que mientras el año es menor, la condición actual reduce.
- La zona donde se encuentra la casa también está ligeramente relacionada a la calidad de los materiales.

Continuamos con un segundo diagrama
```{r}
correlations <- cor(cleanData[,c("neighborhood", "yearBuilt", "overallCondition", "overallQuality", "pool", "fireplace", "foundationMaterial", "exteriorCondition", "additionalFeature", "livingArea" )], use="pairwise.complete.obs")
corrplot(correlations, method="circle", type="lower",  sig.level = 0.01, insig = "blank")
```
Este diagrama nos da otra información de las variables:
- Mientras mejor sea la condición del exterior, mejor es la condición en general de la casa.
- la pisicna está ligeramente correlacionada con tener una fogata y con la condición del exterior de la casa.
- El material usado para la base de la casa está relacionado con el año de construcción de esta.
- El area de vivienda de la casa incrementa conforme la calidad de la construcción lo hace.
- Una área de vivienda mayor permite tener más comodidades, como fogata o una piscina.

Si hacemos una gráfica de puntos tomando en cuenta algunas variables importantes podemos obtener más información:
```{r}
pairs(~yearBuilt+overallQuality+overallCondition+livingArea,data=cleanData,
   main="Matriz de correlación")

```
- la calidad de las casas ha mejorado con el paso de los años.
- El área de vivienda aumenta ligeramente con el paso del tiempo.

Tomando este análisis en cuenta, se utilizarán las siguientes variables como candidatas a mejores predicciones:
- yearBuilt - el año de construcción tiene una alta influencia en la calidad de la casa, vecindario donde se encuentra, condición actual y área de vivienda.
- livingArea - el area de vivienda es un factor imporante porque indica cuánto espacio puede ser aprovechado en la casa. No es la misma área que necesita una familia de 2 personas a una de 5. Además, un área mayor permite tener comodidades como piscina o fogata.
- overallQuality - La calidad de la casa también es importante para el precio. Esto nos indica que el material usado es resistente.
- overallCondition - La condición actual de la casa da una mejor impresión al mostrarla a posibles clientes.
- pool - Una piscina aumenta el precio dado que el cliente debe tener presupuesto para mantenerla.
- fireplace - en Iowa (lugar del dataset) hay inviernos con nieve, los clientes agradecerán esta comodidad

## 6. Asegurando resultados consistentes
```{r}
set.seed(5)
```


## 7. Modelo univariable
### Estimación de precio usando el area de vivienda
livingArea se toma como la variable independiente y se utiliza para hacer el modelo univariado de regresión lineal para predecir el precio de las casas.
```{r}
singleVariableModel2 <- lm(salePrice~livingArea, data = trainingSet)
```

### Caracteristicas del modelo univariado entrenado:
```{r}
summary(singleVariableModel2)
```
Los coeficientes en este modelo son significativos. Sin embargo $R^2$ no es considerado alto, por tanto el modelo no logra explicar la variación en salePrice en su mayoria.


Ecuación de regresión:
$salePrice = `r round(singleVariableModel2$coefficients[2],2)`livingArea + `r round(singleVariableModel2$coefficients[1],2)`$  

```{r}
ggplot(data = trainingSet, mapping = aes(x = livingArea, y = salePrice)) +
geom_point(color = "green", size = 2) +
geom_smooth(method = "lm", se = TRUE) +
labs(title = "Precio de venta ~ Área de vivienda", x = "Área de vivienda", y = "Precio de venta") +
theme_bw() + theme(plot.title = element_text(hjust = 0.5))
```

### Analisis de residuales
Ecuación para predecir el precio de venta para el conjunto de prueba.  
```{r}
predSP2<-predict(singleVariableModel2, newdata = testingSet)
```

### Predicción
```{r} 
head(predSP2)
length(predSP2)
```
### Valores de los residuos del modelo
```{r}
head(singleVariableModel2$residuals)
```

### Gráficos para analizar residuales
```{r}
plot(singleVariableModel2)
```
En el gráfico ***Residuals vs Fitted*** se puede ver que los datos se encuentran alrededor de 0 pero no de forma aleatoria especificamente ya que la mayor cantidad de puntos se centran en un lugar en específico.


### Chequeo de distribución aleatoria de los puntos:
```{r}
hist(singleVariableModel2$residuals)
boxplot(singleVariableModel2$residuals)
qqnorm(singleVariableModel2$residuals)
qqline(singleVariableModel2$residuals, col="red")
```
Según los gráficos se puede observar que en el histograma obtenido no tiene una forma normal, ya que los datos se encuentran distribuidos hacia la derecha. Por otra parte en el gráfico q-q los extremos se alejan de la línea y en la caja de bigotes se observa que hay varios datos que se encuentran en los extremos.


```{r}
library(nortest)
lillie.test(singleVariableModel2$residuals)
```
Haciendo una prueba de normalidad el valor de p es menor que 0.05 por tanto la hipótesis nula de normalidad se rechaza y se afirma que los datos de los residuos no siguen una distribución normal. 


### Precio de venta para el conjunto de prueba
```{r}
predSPP2<-predict(singleVariableModel2, newdata = testingSet[,c(19,21)])
library(caret)
RMSE(predSPP2,testingSet$salePrice)
```

```{r}
plot(testingSet$salePrice,col="blue")
points(predSPP2, col="red")
```

```{r}
summary(testingSet$salePrice-predSPP2)
```
En base a los resultados anteriores no se puede afirmar que se tenga una buena distribución ya que el RMSE es bastante alto, los datos en el gráfico se encuentran principalmente en la parte inferior del gráfico y no en diagonal. Además, en el resumen de estadisticas no se encuentran alrededor de 0 y tienen valores muy altos.



## 8. Modelo multivariable
Utilizamos todas las variables como una primera aproximación.


```{r}
allVariablesModel <- lm(salePrice ~ ., data=trainingSet)
summary(allVariablesModel)
```
El valor de R cuadrado con este modelo es de `0.8231`. Un valor arriba de 0.7 es considerado bueno para problemas de correlación. (Fernando, 2021) https://www.investopedia.com/terms/r/r-squared.asp#:~:text=In%20finance%2C%20an%20R%2DSquared,depend%20on%20the%20specific%20analysis.


Prediciendo valores con este modelo

``` {r}
predictionAllVariables <- predict(allVariablesModel, testingSet, type="response")
allVariablesOutput <- cbind(testingSet, predictionAllVariables)
```

Observando primeros valores de la predicción

```{r}
head(allVariablesOutput[,c("salePrice", "predictionAllVariables")])
```


```{r}
plot(allVariablesModel)
```
La gráfica de Residuales vs Fitted no presenta los valores distribuídos aleatoriamente de manera horizontal centrados en `y=0`. Sin embargo, tampoco está del todo mal si consideramos el valor de R cuadrado. La gráfica `Q-Q` también nos da información útil: paraece que los valores se aproximan a una línea recta entre los cuartiles teóricos -2 y 2.


```{r}
complete_predicted <- na.omit(allVariablesOutput)
rmseAllVariables <- rmse(complete_predicted$salePrice,complete_predicted$prediction)
```

El valor del RMSE es `49481.26`.


## 9. Analizando el modelo

Graficamos la matríz de correlación para todas las variables del modelo.

```{r}

modelCorrelations <- cor(allVariablesOutput, method="pearson")
modelCorrelations[is.na(modelCorrelations)] <- 0

corrplot(modelCorrelations, type="upper", order="hclust", tl.col="black", tl.srt=45)

```


En el resumen generado arriba se puede observar que las variables más significativas son: neighborhood, remodelated, roofStyle, overallQuality, overallCondition, garageArea, pool, livingArea, yearBuilt.

La gráfica de los valores ajustados vs los residuales nos indica que el modelo puede tener un problema de overfitting. Es decir, no logrará generalizar correctamente los valores del set te prueba.

## 10. Modelo con variables significativas
```{r}

newMultivariableModel <- lm(salePrice ~ neighborhood + remodelated + roofStyle + overallQuality + overallCondition + garageArea + livingArea + yearBuilt, data=trainingSet)
summary(newMultivariableModel)
```

```{r}
plot(newMultivariableModel)
```

La reducción de variables disminuyó el sobreajuste. Sin embargo, también disminuyó el valor de R cuadrado a 0.81. Hay que tomar en cuenta que esto es para los datos de entrenamiento, así que pondremos a prueba al modelo:
``` {r}
newModelPrediction <- predict(newMultivariableModel, testingSet, type="response")
newModelOutput <- cbind(testingSet, newModelPrediction)
```

Observando primeros valores de la predicción

```{r}
head(newModelOutput[,c("salePrice", "newModelPrediction")])
```

```{r}
completeNewModelPredicted <- na.omit(newModelOutput)
rmseNewModel <- rmse(completeNewModelPredicted$salePrice,completeNewModelPredicted$newModelPrediction)
```

El valor del RMSE es `45207.99`. Lo cuál es menor al valor del modelo anterior (49481.26). Esto es un indicador que el nuevo modelo es mejor generalizando la información.


## 11. Modelos con conjunto de pruebas

### Modelo 1 - Univariable
```{r}
svmodel7 <- lm(salePrice~livingArea, data = testingSet)
```

### Caracteristicas del modelo univariado entrenado:
```{r}
summary(svmodel7)
```
Podemos ver que $R^2$ (0.46) es más bajo que cuando se utilizó el conjunto de entrenamiento ($R^2$) por tanto la eficiencia del algoritmo para predecir el precio de las casas es menor y la regresión lineal se acopla de menor forma al conjunto de datos.

### Modelo 2 - Multivariable

```{r}
allVM8 <- lm(salePrice ~ ., data=testingSet)
summary(allVM8)
```
El valor de $R^2$ con este modelo es de `0.75` y aunque es menor a cuando se utilzó el conjunto de entrenamiento ($R^2$ = 0.8231) Aún es considerado aceptable para problemas de correlación. (Fernando, 2021) https://www.investopedia.com/terms/r/r-squared.asp#:~:text=In%20finance%2C%20an%20R%2DSquared,depend%20on%20the%20specific%20analysis.

### Modelo 3 - Multivariable con variables significativas
```{r}
allVM10 <- lm(salePrice ~ neighborhood + remodelated + roofStyle + overallQuality + overallCondition + garageArea + livingArea + yearBuilt, data=testingSet)
summary(allVM10)
```
En este caso a pesar de $R^2$ (0.72) aún es considerado aceptable para problemas de correlación (Fernando, 2021) su valor fue reducido considerablemente vs si se hubiera hecho con el conjunto de datos de entrenamiento (0.81).
https://www.investopedia.com/terms/r/r-squared.asp#:~:text=In%20finance%2C%20an%20R%2DSquared,depend%20on%20the%20specific%20analysis.

Es posible concluir que para los modelos tanto univariables como multivariables la eficiencia del modelo se ve reducida y un menor $R^2$ nos indica que el modelo que el modelo se ajusta menos a los datos y por tanto hay una menor precisión en la predicción de los datos.


## 12. Efectividad de modelos


```{r echo = FALSE, result = 'asis'}
firstColumn <- c( 0.52, 0.8231,  0.813)

dataSource <- data.frame(modelo = c("Lineal", "Multivariable", "Multivariable Significativas"), rCuadrado=firstColumn)

kable(dataSource)

```

 El valor de R cuadrado pareciera ser mejor en el modelo Multivariable que usa todas las variables numérics. Sin embargo, hay que tomar en cuenta que esta medida es para el set de entrenamiento. Si se observa el análisis de residuales para ese modelo se ve que este está sobreajustado.
 
#### Graficando Modelo Univariable (con LivingArea)
``` {r echo = FALSE}
plot(testingSet$salePrice,col="blue", ylab="SalePrice", xlab="Observacion")
points( predSP2, col="red")
```
 
#### Graficando Modelo Multivariable 
 
``` {r echo = FALSE}
plot(testingSet$salePrice,col="blue", ylab="SalePrice", xlab="Observacion")
points(predictionAllVariables, col="red")
```
 En azul tenemos el precio correcto y en rojo los valores predecidos para ese mismo conjunto de datos. Podemos observar que el modelo no es muy bueno generalizando precios muy altos. Lo cuál confirma la forma que se ve en la gráfica de residuales.
 

#### Graficando Modelo Multivariable con variables significativas

``` {r echo = FALSE}
plot(testingSet$salePrice,col="blue", ylab="SalePrice", xlab="Observacion")
points(newModelPrediction, col="red")
```
Este modelo a pesar de ser parecido al anterior puede generaizar mejor los valores de prueba. Esto se ve claramente en las observaciones con precios bajos.

Por otro lado, al comparar el RMSE de los modelos (62571.91, 49481.26 y 45207.99), obtenemos que el tercero tiene un menor valor, es decir, es un indicador que es mejor generalizando los resultados. 

En conclusión, el modelo que mejor generaliza los precios de las casas es el modelo multivariable que utiliza únicamente las variables importantes: neighborhood, remodelated, roofStyle, overallQuality, overallCondition, garageArea, pool, livingArea, yearBuilt. Hay que tomar en cuenta que podríamos tener mejores resultados utilizando un modelo polinómico en vez de lineal porque algunas características, como livingArea no crecen de forma lineal.


